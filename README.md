# ğŸœ Evolutionary Ant Simulation: GA vs PSO Neural Network Foraging

**A fun, interactive p5.js simulation demonstrating how neural networks can be optimized using evolutionary algorithms â€” no backpropagation required.**

## ğŸ¯ Overview

This project visualizes two colonies of ants â€” one powered by **Genetic Algorithms (GA)** and the other by **Particle Swarm Optimization (PSO)** â€” as they compete to find food in a shared environment.

Each ant is controlled by a simple **neural network brain** that takes sensory input (like nearby food direction) and decides how to move.  
Instead of using gradient descent or backpropagation, the antsâ€™ neural weights are tuned using **evolutionary methods**.

> Backpropagation isnâ€™t the only way to make neural networks learn!

## ğŸ§¬ Core Concepts

| Concept                               | Description                                                                    |
| ------------------------------------- | ------------------------------------------------------------------------------ |
| **Neural Networks**                   | Each ant has a tiny feedforward network controlling its movement.              |
| **Genetic Algorithm (GA)**            | Red ants evolve via selection, crossover, and mutation based on fitness.       |
| **Particle Swarm Optimization (PSO)** | Blue ants adjust their weights based on personal and global best performances. |
| **Fitness Function**                  | The more food an ant collects, the higher its fitness.                         |
| **Emergent Behavior**                 | Over generations, each team should learn to forage more efficiently.           |

## ğŸ•¹ï¸ Try It Out

You can run this project directly in your browser using the [p5.js online editor](https://editor.p5js.org):

1. Copy the contents of [`main.js`](./src/main.js) and [`index.html`](./index.html).
2. Paste them into [editor.p5js.org](https://editor.p5js.org).
3. Press â–¶ï¸ **Run** to start the simulation.
4. Click on the canvas to add new food sources!

## ğŸ§  How It Works

Each frame, every ant:

1. **Senses** nearby food within a certain radius.
2. **Feeds inputs** (angle, distance, etc.) into its neural network.
3. **Receives outputs**: steering direction and speed.
4. **Moves**, collects food, and earns a fitness score.

Every few seconds (a generation):

- GA ants reproduce using selection, crossover, and mutation.
- PSO ants update their neural weights based on swarm dynamics.
- Fitness scores are reset, and evolution continues.

## ğŸ“ˆ Example Roadmap

### âœ… Version 1 â€” Baseline Simulation

- Environment, ants, food, fitness tracking
- Clicking adds food
- Two teams (red = GA, blue = PSO)

### ğŸš§ Version 2 â€” Learning Systems

- Neural network brains
- GA selection, crossover, mutation
- PSO swarm update logic

### ğŸ”¬ Version 3 â€” Visualization

- Fitness graphs and statistics
- Highlight top-performing ants
- Sliders for mutation rate, swarm size, etc.

### ğŸŒŸ Version 4 â€” Polish

- Save/load best ants
- Obstacle placement
- Real-time weight visualization

## ğŸ’¡ Why This Project Exists

When teaching about neural networks, students often learn **backpropagation** as the only training method.  
This project demonstrates that **evolutionary computation** â€” through GA or PSO â€” can also discover effective network weights, even when gradients are unavailable or non-differentiable.

Itâ€™s a fun way to explore **AI without calculus**, and a great foundation for learning about:

- Emergent behavior in agent-based systems
- Alternative optimization strategies
- Interactive, visual AI experiments

## ğŸ§° Tech Stack

- **JavaScript / p5.js** â€” rendering and simulation logic
- **dat.GUI (optional)** â€” for live parameter tuning
- **HTML/CSS** â€” for embedding and controls
